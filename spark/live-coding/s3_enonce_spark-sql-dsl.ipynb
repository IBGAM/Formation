{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad5563ba-b8d9-46fd-a485-ceb4735e2c21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Dans ce TP, nous considérons des trajets en vélo partagé (similaire au vélib) en Californie. Deux jeux de données sont fournis : l'un qui contient les stations de vélo, l'autre, les trajets à vélo. Les déplacements à vélo se font d'une station à l'autre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf7dc796-dd34-42c2-8c22-93f6b85ad47c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Charger le fichier stationData.csv dans un DataFrame station_df et le fichier tripData.csv dans un DataFrame trip_df. Pour chaque Dataframe, il vous faudra demander une inférence des schémas et indiquer que la première ligne est un en-tête."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "436bbfc0-b90d-4202-8e9f-55099321d9ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/stationData.csv</td><td>stationData.csv</td><td>5272</td><td>1732186175000</td></tr><tr><td>dbfs:/FileStore/tables/tripData.csv</td><td>tripData.csv</td><td>43012642</td><td>1732186272000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/tables/stationData.csv",
         "stationData.csv",
         5272,
         1732186175000
        ],
        [
         "dbfs:/FileStore/tables/tripData.csv",
         "tripData.csv",
         43012642,
         1732186272000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {
        "isDbfsCommandResult": false
       },
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%fs ls /FileStore/tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e16c876c-9976-44fe-98f3-734d50127afa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "station_df = spark.read.csv(\"/FileStore/tables/stationData.csv\", inferSchema=True, header=True)\n",
    "trip_df = spark.read.option(\"inferSchema\",\"true\").csv(\"/FileStore/tables/tripData.csv\",header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7af2f8ad-32d3-4d66-9862-b0d2c55e15e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Afficher les schémas des 2 DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c2e4af7-8c45-4a58-9965-f600074ca648",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- TripID: integer (nullable = true)\n |-- Duration: integer (nullable = true)\n |-- StartDate: string (nullable = true)\n |-- StartStation: string (nullable = true)\n |-- StartTerminal: integer (nullable = true)\n |-- EndDate: string (nullable = true)\n |-- EndStation: string (nullable = true)\n |-- EndTerminal: integer (nullable = true)\n |-- Bike#: integer (nullable = true)\n |-- SubscriberType: string (nullable = true)\n |-- ZipCode: string (nullable = true)\n\nroot\n |-- station_id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- lat: double (nullable = true)\n |-- long: double (nullable = true)\n |-- dockcount: integer (nullable = true)\n |-- landmark: string (nullable = true)\n |-- installation: date (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "trip_df.printSchema()\n",
    "\n",
    "station_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b35305b3-5b4b-411a-80dd-9315b3b8c743",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Créer une vue pour chaque DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "efee527c-afbe-413d-88f6-d75be200eee3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Votre code ici\n",
    "#display(trip_df)\n",
    "\n",
    "station_df.createOrReplaceTempView(\"station\")\n",
    "trip_df.createOrReplaceTempView(\"trip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1cb92e5c-797b-4cad-8392-722d513cfb38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Trouver deux façons de calculer le nombre de trajets, l'une en appelant une méthode sur trip_df directement, l'autre en rédigeant une requête SQL de la vue correspondant au DataFrame tripData."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b50b63fd-c346-4158-bc06-3b8100194f24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n|count(1)|\n+--------+\n|  354152|\n+--------+\n\n"
     ]
    }
   ],
   "source": [
    "# Votre code ici\n",
    "trip_df.count()\n",
    "\n",
    "spark.sql(\"select count(1) from trip\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88e8bd91-78fc-4248-8066-ac6b3ece7dfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Ecrire une requête permettant de compter le nombre de trajets qui démarrent et se terminent à la même station."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6365c23a-ec09-4ff6-a926-3d8e630c1598",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n|count(1)|\n+--------+\n|   10276|\n+--------+\n\n"
     ]
    }
   ],
   "source": [
    "# Votre code ici\n",
    "spark.sql(\"select count(1) from trip where StartTerminal=EndTerminal\").show()\n",
    "\n",
    "#trip_df.filter(trip_df['StartTerminal']==trip_df['EndTerminal']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cb480a36-196d-4d88-bd35-12b4ab058136",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "On souhaite désormais obtenir l’id des stations associées à ces trajets. Ecrire une requête renvoyant la liste des terminaux concernés ainsi que le nombre de trajets pour chacun de ces terminaux. Trier le résultat par ordre décroissant de nombre de trajets.\n",
    "<br>Exemple de sortie :\n",
    "<br>+--------+--------+\n",
    "<br>|terminal|count(1)|\n",
    "<br>+--------+--------+\n",
    "<br>| 60| 850|\n",
    "<br>| 50| 708|\n",
    "<br>| 35| 348|\n",
    "<br>| 76| 320|\n",
    "<br>| 74| 307|\n",
    "<br>(La station 60 est la plus concernée par ces trajets cycliques, avec 850 de ces trajets.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5c766cd-b7b6-48bf-a516-89eb0ca26aed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n|StartTerminal|count(1)|\n+-------------+--------+\n|           60|     850|\n|           50|     708|\n|           35|     348|\n|           76|     320|\n|           74|     307|\n|           39|     296|\n|           61|     280|\n|           67|     277|\n|           71|     268|\n|           70|     260|\n|           28|     254|\n|           48|     248|\n|           54|     230|\n|           69|     227|\n|           42|     213|\n|           73|     200|\n|           57|     197|\n|           64|     194|\n|            3|     189|\n|           72|     181|\n+-------------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Votre code ici\n",
    "spark.sql(\"select StartTerminal, count(1) from trip where StartTerminal=EndTerminal group by StartTerminal order by 2 desc;\").show()\n",
    "\n",
    "#trip_df.filter(trip_df['StartTerminal']==trip_df['EndTerminal']).groupBy(trip_df['StartTerminal']).count(orderBy(desc(\"count\"))).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5512115f-f2b2-4fef-a466-0847a7ea61c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Dans la requête précédente, nous avons oublié un élément qui nous importe. Nous souhaitons compléter le résultat en indiquant le nombre de docks (dockcount) des stations concernées.\n",
    "<br>Exemple de sortie :\n",
    "<br>+--------+---------+--------+\n",
    "<br>|terminal|dockcount|count(1)|\n",
    "<br>+--------+---------+--------+\n",
    "<br>| 60| 15| 850|\n",
    "<br>| 50| 23| 708|\n",
    "<br>| 35| 11| 348|\n",
    "<br>| 76| 19| 320|\n",
    "<br>| 74| 23| 307|\n",
    "<br>Mettre à jour la requête."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b4a2b7f-a932-4575-bdc4-d15593a184f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+--------+\n|StartTerminal|dockcount|count(1)|\n+-------------+---------+--------+\n|           60|       15|     850|\n|           50|       23|     708|\n|           35|       11|     348|\n|           76|       19|     320|\n|           74|       23|     307|\n|           39|       19|     296|\n|           61|       27|     280|\n|           67|       27|     277|\n|           71|       19|     268|\n|           70|       19|     260|\n|           28|       23|     254|\n|           48|       15|     248|\n|           54|       15|     230|\n|           69|       23|     227|\n|           42|       15|     213|\n|           73|       15|     200|\n|           57|       15|     197|\n|           64|       15|     194|\n|            3|       15|     189|\n|           72|       23|     181|\n+-------------+---------+--------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Votre code ici\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "    select StartTerminal, dockcount, count(1) from trip, station where StartTerminal=EndTerminal and StartTerminal=station_id group by StartTerminal,dockcount order by 3 desc;\n",
    "    \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "85ca6c3d-0c56-4e48-9a52-d5e726699e1c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Rédiger les 2 requêtes précédentes avec le DSL de DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c956dd4-dab0-4c4e-94f8-5c46cf63f004",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------+-----+\n|StartTerminal|dockcount|count|\n+-------------+---------+-----+\n|           60|       15|  850|\n|           50|       23|  708|\n|           35|       11|  348|\n|           76|       19|  320|\n|           74|       23|  307|\n|           39|       19|  296|\n|           61|       27|  280|\n|           67|       27|  277|\n|           71|       19|  268|\n|           70|       19|  260|\n|           28|       23|  254|\n|           48|       15|  248|\n|           54|       15|  230|\n|           69|       23|  227|\n|           42|       15|  213|\n|           73|       15|  200|\n|           57|       15|  197|\n|           64|       15|  194|\n|            3|       15|  189|\n|           72|       23|  181|\n+-------------+---------+-----+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, desc\n",
    "\n",
    "\n",
    "#trip_df.filter(trip_df['StartTerminal']==trip_df['EndTerminal']).groupBy(trip_df['StartTerminal']).count(orderBy(desc(\"count\"))).show()\n",
    "\n",
    "\n",
    "res = trip_df.join(\n",
    "    station_df,\n",
    "    on=col(\"StartTerminal\")==col(\"station_id\"),\n",
    "    how=\"left\"\n",
    ").filter(col(\"StartTerminal\")==col(\"EndTerminal\")\n",
    ").groupBy(\n",
    "    \"StartTerminal\",\n",
    "    \"dockcount\",\n",
    ").count(\n",
    ").orderBy(\n",
    "    desc(\"count\")\n",
    ")\n",
    "\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b61df3b-6e86-4145-a96d-92cba40f5f3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Votre code ici"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c25a1c70-14b9-48dd-9f8d-96e8d6e7eec2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Observer le plan d’exécution des requêtes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82b85a3c-55f6-42dc-be19-a0099d957fa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\nAdaptiveSparkPlan isFinalPlan=false\n+- Sort [count#1178L DESC NULLS LAST], true, 0\n   +- Exchange rangepartitioning(count#1178L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=2565]\n      +- Project [StartTerminal#273, dockcount#242, count(1)#1177L AS count#1178L]\n         +- HashAggregate(keys=[StartTerminal#273, dockcount#242], functions=[finalmerge_count(merge count#1192L) AS count(1)#1177L])\n            +- Exchange hashpartitioning(StartTerminal#273, dockcount#242, 200), ENSURE_REQUIREMENTS, [plan_id=2561]\n               +- HashAggregate(keys=[StartTerminal#273, dockcount#242], functions=[merge_count(merge count#1192L) AS count#1192L])\n                  +- Project [StartTerminal#273, dockcount#242, count#1192L]\n                     +- BroadcastHashJoin [StartTerminal#273], [station_id#238], LeftOuter, BuildRight, false, true\n                        :- HashAggregate(keys=[StartTerminal#273], functions=[partial_count(1) AS count#1192L])\n                        :  +- Project [StartTerminal#273]\n                        :     +- Filter ((isnotnull(StartTerminal#273) AND isnotnull(EndTerminal#276)) AND (StartTerminal#273 = EndTerminal#276))\n                        :        +- FileScan csv [StartTerminal#273,EndTerminal#276] Batched: false, DataFilters: [isnotnull(StartTerminal#273), isnotnull(EndTerminal#276), (StartTerminal#273 = EndTerminal#276)], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/FileStore/tables/tripData.csv], PartitionFilters: [], PushedFilters: [IsNotNull(StartTerminal), IsNotNull(EndTerminal)], ReadSchema: struct<StartTerminal:int,EndTerminal:int>\n                        +- Exchange SinglePartition, EXECUTOR_BROADCAST, [plan_id=2556]\n                           +- Filter isnotnull(station_id#238)\n                              +- FileScan csv [station_id#238,dockcount#242] Batched: false, DataFilters: [isnotnull(station_id#238)], Format: CSV, Location: InMemoryFileIndex(1 paths)[dbfs:/FileStore/tables/stationData.csv], PartitionFilters: [], PushedFilters: [IsNotNull(station_id)], ReadSchema: struct<station_id:int,dockcount:int>\n\n\n"
     ]
    }
   ],
   "source": [
    "# Votre code ici\n",
    "res.explain()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 367402056848828,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "s3_enonce_spark-sql-dsl",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
